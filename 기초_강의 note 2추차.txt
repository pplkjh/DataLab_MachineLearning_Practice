2주차
ㅇ분산 = 평균을 기준으로 그 차이가 얼마나 많이 나는지에 대한 척도 =  편차 제곱의 평균 ==>(Σ(x-x̅)²/n)(제곱된 값이므로 값이 크다.)
	->√분산 = 표준편차  ==> √(Σ(x-x̅)²/n)

ㅇ점추정: 임의의 샘플의 결과값을 모집단의 값과 같을것이라고 추정(보통 알고리즘에서 보통사용)
ㅇ구간추정: 확률을 이용해서 신뢰구간을 만들어 값이 그 구간안에 있다고 추정

ㅇCSV 파일: Comma Seperated Value, 데이터에 비해 용량이 작다.

ㅇ대량의 데이터로 허리둘레에 영향을 미치는 요인 찾기
1.목적에 필요없는 항목들 제거
2.누락된 데이터가 많은 항목과 샘플 제거
3.outlier제거
4.class가 나뉘어 그 변수의 요인이 분명하거나 값에 큰 영향을 미칠 수있는 항목들을 따로 분류
5.알고리즘 정리: 영향을 미치는 요인이라는 것을 정의 하기 위하여 유사도 계산(관계성), 상관분석을 위하여 단위를 각 항목들의 단위(scale)를 통일시켜야 한다 
=>rescaling : 각 항목들의 최대값으로 나누어 0~1 사이의 값으로 만든다.
6.데이터간 관계성을 파악하여 예측한다. 이 방정식을 찾는 것이 머신러닝의 목표.
**요구조건과 데이터

ㅇ영가설 검정(Zero-hypothesis,H0, 귀무가설): 내가 목표로 하는 것의 반대를 가설로 세우고 그 가설이 거짓일때 실제 목표의 가설이 참이라고 판단.
 => 내 주장의 역의 확률을 본다.
 ex) 인간의 수면시간은 7시간정도이다 라는 가설을 위해 -> 그 역인 인간의 수면시간은 2시간이나 12시간이다 라는 가설을 증명
	=> 이 가설이 거짓일때 인간의 수면시간은 7시간 정도가 맞다라는 가설이 옳다
 α(알파)기준선: 가설을 채택할 기준선 -- α=0.05 =>예외가 나올 확률이 5%로 이하면 채택
 H0: true(영가설이 참이라고 가정)일때 P-value(검정통계량): 실제로 관측된 확률, 귀무가설을 얼마나 지지하는지를 확률로 나타낸것
 P-value 가 α밖에 있다면 귀무가설 채택