ㅇ빅데이터를 효율적으로 활용하기 위해선
->데이터의 더미속에서 어떤 데이터를 쓸지 선택하기 전 구체적으로 목표를 잡는것이 우선.

ㅇ데이터의 수집은 오래전 부터 가능했지만 근래들어 이슈가 된 이유는
->이제는 대량의 데이터를 활용할 능력과 인프라, 기술이 받쳐주기때문, 활용하여 사용할 수 있는 새로운 데이터로 가공할 수 있다는 점이 차이점

ㅇ빅데이터 분석을 위한 도구
R ->시각화가 우수하다, 호환이 힘듦
Python -> 배우기 쉽고 연동이 용이하다.

ㅇ머신러닝 : 1. 예측: 값으로 나온다.		|
	     2. 분류 : 카테고리로 나온다		|

ㅇ개와 고양이 문제로 배운것
1.과거에 해오던 방법, 조건문을 사용한 분류법: 특징과 조건을 정해놓고 부합하는 쪽으로 분류 -> 예외가 있거나 벗어난 값에 관하여 일일이 지정해 주어야 한다. (비효율, 불가능)
2. 현재, CNN(Convolutional Neural Network) 이미지 데이터 학습에 적합 : raw데이터를 그대로 쓰지 않고 특징들만 모아서 압축(Convolution[특징 추출] & Pooling[최대특징 선택])

==> 기존엔 조건을 일일히 정해줬다면, 머신러닝은 목표를 던져주고 컴퓨터가 자가 학습을 통해 결과가 도출 되도록 한다.( 정답이 있는 경우의 학습, 지도 학습)

ㅇ통계 : 
우리의 목적은 모집단(population: 사실상 얻을수 없는 전체 데이터)에서 모집단의 평균(μ)과 모집단의 표준편차(σ) 이지만 모집단의 전체 데이터를 얻을 수 없기에 표본(Sample)을 표집(sampling)한다. 이때 공정한 표집을 위해 무선표집(random sampling)이 이루어 져야 하며, 중심극한정리(CLT: Central Limit Theorem)에 의해 표집수(N)가 많을 수록 모집단의 분포와 비슷해 지고 편향(bias: 데이터의 치우침 양상)이 줄어들고, 자동으로 정규분포(좌우대칭 종모양)의 모양이 나올것이다. 이렇게 얻어진 표본의 평균(x-bar)과 표본의 표준편차(S)를 구하고 이렇게 구해진 기술통계의 데이터를 추론통계 하는것이 머신러닝의  방법이다.

ㅇ 구하려는 통계의 값이 무엇을 위한 것인지, 장단점이 무엇인지 파악이 중요하다
-> 수치적 가운데 (평균: mean)
-> 순서로서의 가운데 (중앙치: median)
-> 빈도에서의 최고 빈도(최빈치: mode)